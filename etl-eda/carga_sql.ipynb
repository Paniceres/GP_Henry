{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Funciones</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def conectar_base_oficial():\n",
    "    try:\n",
    "        conexion = mysql.connector.connect(\n",
    "            host='quantyle.cxqm3ttktdpq.us-east-2.rds.amazonaws.com',\n",
    "            user='admin',\n",
    "            password='1533542415',\n",
    "            database='quantyle'\n",
    "        )\n",
    "        print(\"¡Conexión establecida correctamente!\")\n",
    "        return conexion\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Error al conectarse a MySQL:\", error)\n",
    "        return None'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectar_mysql():\n",
    "    try:\n",
    "        conexion = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='1533542415',\n",
    "            database='quantyle_analitics'\n",
    "        )\n",
    "        print(\"¡Conexión establecida correctamente!\")\n",
    "        return conexion\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Error al conectarse a MySQL:\", error)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n",
      "Conexión exitosa\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexión con la base de datos\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Verificar si la conexión se realizó con éxito\n",
    "if conexion.is_connected():\n",
    "    print(\"Conexión exitosa\")\n",
    "\n",
    "# Realizar operaciones en la base de datos, por ejemplo, ejecutar una consulta SQL\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejemplo de consulta SQL\n",
    "consulta = \"SELECT * FROM categories_yelp\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "cursor.execute(consulta)\n",
    "\n",
    "# Obtener los resultados\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for fila in resultados:\n",
    "    print(fila)\n",
    "\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n",
      "Conexión exitosa\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexión con la base de datos\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Verificar si la conexión se realizó con éxito\n",
    "if conexion.is_connected():\n",
    "    print(\"Conexión exitosa\")\n",
    "\n",
    "# Realizar operaciones en la base de datos, por ejemplo, ejecutar una consulta SQL\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejemplo de consulta SQL\n",
    "consulta = \"SELECT * FROM categories_yelp\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "cursor.execute(consulta)\n",
    "\n",
    "# Obtener los resultados\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for fila in resultados:\n",
    "    print(fila)\n",
    "\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "state = pd.read_parquet(r'..\\datasets\\processed\\bd\\1_states.parquet.gz')\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla state\n",
    "cursor = conexion.cursor()\n",
    "for index, row in state.iterrows():\n",
    "    cursor.execute(\"INSERT INTO state (state) VALUES (%s)\", (row['state'],))  # Asegúrate de tener la coma al final\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_parquet(r'..\\datasets\\processed\\bd\\2_categories.parquet.gz')\n",
    "\n",
    "# Aplicar strip() a la columna 'name' para eliminar espacios en blanco adicionales\n",
    "categories['name'] = categories['name'].str.strip()\n",
    "\n",
    "# Convertir la columna 'name' a minúsculas para uniformizar los datos\n",
    "categories['name'] = categories['name'].str.lower()\n",
    "\n",
    "# Eliminar las filas duplicadas basadas en la columna 'name'\n",
    "categories.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla categories\n",
    "cursor = conexion.cursor()\n",
    "for index, row in categories.iterrows():\n",
    "    cursor.execute(\"INSERT INTO categories (categories_id , name) VALUES (%s, %s)\", (row['categories_id'], row['name'],))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) User yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "user_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\3_user_yelp.parquet.gz')\n",
    "user_yelp['creation'] = user_yelp['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla bussiness_yelp\n",
    "cursor = conexion.cursor()\n",
    "for index, row in user_yelp.iterrows():\n",
    "    cursor.execute(\"INSERT INTO user_yelp (user_id, name, creation, review_count, influence, stars) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                (row['user_id'], row['name'], row['creation'], row['review_count'], row['influence'], row['stars']))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) User google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "user_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\4_user_google.parquet.gz')\n",
    "user_google['creation'] = user_google['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "user_google.drop_duplicates(inplace=True)\n",
    "user_google['user_id'] = user_google['user_id'].astype(str)\n",
    "user_google['name'] = user_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "user_google.drop(2023700,inplace=True)\n",
    "user_google.dropna(inplace=True)\n",
    "user_google = user_google.groupby(['user_id','name','creation','review_count'])['stars'].mean().reset_index()\n",
    "user_google = user_google.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in user_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    user_google[column] = user_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla bussiness_yelp\n",
    "cursor = conexion.cursor()\n",
    "for index, row in user_google.iterrows():\n",
    "    cursor.execute(\"INSERT INTO user_google (user_id, name, creation, review_count, stars) VALUES (%s, %s, %s, %s, %s)\",\n",
    "                (row['user_id'], row['name'], row['creation'], row['review_count'], row['stars']))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Bussiness google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "business_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\5_business_google.parquet.gz')\n",
    "\n",
    "\n",
    "business_google.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"California\", 2)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_google['name'] = business_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_google.dropna(inplace=True)\n",
    "business_google = business_google.drop_duplicates(subset=['gmap_id'], keep='first')\n",
    "business_google.drop(22003,inplace=True)\n",
    "business_google['avg_stars'] = business_google['avg_stars'].round(2)\n",
    "\n",
    "business_google = business_google[business_google['gmap_id'].isin(categories_google['gmap_id'].unique())]\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_google[column] = business_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in business_google[['gmap_id', 'name', 'latitude', 'longitude', 'avg_stars', 'state_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO business_google (gmap_id, name, latitude, longitude, avg_stars, state_id) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Business yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "business_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\6_business_yelp.parquet.gz')\n",
    "\n",
    "business_yelp.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_yelp.rename(columns={'stars': 'avg_stars'}, inplace=True)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"California\", 2)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_yelp['name'] = business_yelp['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_yelp.dropna(inplace=True)\n",
    "business_yelp = business_yelp.drop_duplicates(subset=['business_id'], keep='first')\n",
    "business_yelp['avg_stars'] = business_yelp['avg_stars'].round(2)\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_yelp[column] = business_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in business_yelp[['business_id', 'name', 'latitude', 'longitude', 'avg_stars', 'state_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO business_yelp (business_id, name, latitude, longitude, avg_stars, state_id) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Categories google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "\n",
    "categories_google = categories_google[categories_google['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_google = categories_google[categories_google['gmap_id'].isin(business_google['gmap_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_google[column] = categories_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "    \n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in categories_google[['gmap_id', 'categories_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO categories_google (gmap_id, categories_id) VALUES (%s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Categories yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\8_categories_yelp.parquet.gz')\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_yelp[column] = categories_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in categories_yelp[['business_id', 'categories_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO categories_yelp (business_id, categories_id) VALUES (%s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Reviews google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\9_reviews_google.parquet.gz')\n",
    "\n",
    "reviews_google['date'] = reviews_google['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "reviews_google['resp_date'] = reviews_google['resp_date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_google['user_id'] = reviews_google['user_id'].astype(str)\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "reviews_google.loc[reviews_google['resp_date'].isna(), 'resp_date'] = reviews_google.loc[reviews_google['resp_date'].isna(), 'date']\n",
    "\n",
    "\n",
    "def round_resp_sentiment(value):\n",
    "    if value < -0.5:\n",
    "        return 0\n",
    "    elif -0.5 <= value < 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].apply(round_resp_sentiment)\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].astype(str)\n",
    "\n",
    "\n",
    "# export\n",
    "# reviews_google.to_csv(r'reviews_google.csv',encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_google.csv'\n",
    "INTO TABLE reviews_google\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, gmap_id, stars, sentiment, date, resp_sentiment, resp_date);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Reviews yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\10_reviews_yelp.parquet.gz')\n",
    "\n",
    "reviews_yelp['date'] = reviews_yelp['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['user_id'].isin(user_yelp['user_id'])]\n",
    "\n",
    "\n",
    "#reviews_yelp.to_csv(r'reviews_yelp.csv',encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_google.csv'\n",
    "INTO TABLE reviews_google\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, gmap_id, stars, sentiment, date, resp_sentiment, resp_date);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_yelp.csv'\n",
    "INTO TABLE reviews_yelp\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, business_id, stars, sentiment, date);'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>state_id</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>39144818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>39250017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>39399349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>39538223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>39613506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date state_id  Population\n",
       "0  2015        2    39144818\n",
       "1  2016        2    39250017\n",
       "2  2017        2    39399349\n",
       "3  2018        2    39538223\n",
       "4  2019        2    39613506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Crear el DataFrame original con los datos proporcionados\n",
    "data = {\n",
    "    '2': [39144818, 39250017, 39399349, 39538223, 39613506, 39538223, 39296476, 39056079, 38982847],\n",
    "    '1': [20271272, 20656589, 20984400, 21299325, 21477737, 21538187, 21733312, 22244823, 22733312],\n",
    "    '3': [12859995, 12802503, 12778828, 12741080, 12671821, 12812508, 12671869, 12518144, 12470000],\n",
    "    '4': [8958013, 9005644, 9032872, 8908520, 8882190, 9288994, 9261692, 9288994, 9290000]\n",
    "}\n",
    "\n",
    "index = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Resetear el índice para convertir los años en una columna 'Date'\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "# Convertir el DataFrame a un formato largo (usando melt) para combinar las columnas de población en una sola columna\n",
    "df = df.melt(id_vars='Date', var_name='state_id', value_name='Population')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "# conexion = conectar_base_oficial()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in df[['state_id','Date','Population']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO Population_data (state_id, Date, Population) VALUES (%s, %s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
