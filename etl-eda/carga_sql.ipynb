{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Funciones</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectar_mysql():\n",
    "    try:\n",
    "        conexion = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='1533542415',\n",
    "            database='quantyle_analitics'\n",
    "        )\n",
    "        print(\"¡Conexión establecida correctamente!\")\n",
    "        return conexion\n",
    "    except mysql.connector.Error as error:\n",
    "        print(\"Error al conectarse a MySQL:\", error)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n",
      "Conexión exitosa\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexión con la base de datos\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Verificar si la conexión se realizó con éxito\n",
    "if conexion.is_connected():\n",
    "    print(\"Conexión exitosa\")\n",
    "\n",
    "# Realizar operaciones en la base de datos, por ejemplo, ejecutar una consulta SQL\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejemplo de consulta SQL\n",
    "consulta = \"SELECT * FROM categories_yelp\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "cursor.execute(consulta)\n",
    "\n",
    "# Obtener los resultados\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "# Mostrar los resultados\n",
    "for fila in resultados:\n",
    "    print(fila)\n",
    "\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "state = pd.read_parquet(r'..\\datasets\\processed\\bd\\1_states.parquet.gz')\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla state\n",
    "cursor = conexion.cursor()\n",
    "for index, row in state.iterrows():\n",
    "    cursor.execute(\"INSERT INTO state (state) VALUES (%s)\", (row['state'],))  # Asegúrate de tener la coma al final\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_parquet(r'..\\datasets\\processed\\bd\\2_categories.parquet.gz')\n",
    "\n",
    "# Aplicar strip() a la columna 'name' para eliminar espacios en blanco adicionales\n",
    "categories['name'] = categories['name'].str.strip()\n",
    "\n",
    "# Convertir la columna 'name' a minúsculas para uniformizar los datos\n",
    "categories['name'] = categories['name'].str.lower()\n",
    "\n",
    "# Eliminar las filas duplicadas basadas en la columna 'name'\n",
    "categories.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla categories\n",
    "cursor = conexion.cursor()\n",
    "for index, row in categories.iterrows():\n",
    "    cursor.execute(\"INSERT INTO categories (categories_id , name) VALUES (%s, %s)\", (row['categories_id'], row['name'],))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) User yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "user_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\3_user_yelp.parquet.gz')\n",
    "user_yelp['creation'] = user_yelp['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla bussiness_yelp\n",
    "cursor = conexion.cursor()\n",
    "for index, row in user_yelp.iterrows():\n",
    "    cursor.execute(\"INSERT INTO user_yelp (user_id, name, creation, review_count, influence, stars) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                (row['user_id'], row['name'], row['creation'], row['review_count'], row['influence'], row['stars']))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) User google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "user_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\4_user_google.parquet.gz')\n",
    "user_google['creation'] = user_google['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "user_google.drop_duplicates(inplace=True)\n",
    "user_google['user_id'] = user_google['user_id'].astype(str)\n",
    "user_google['name'] = user_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "user_google.drop(2023700,inplace=True)\n",
    "user_google.dropna(inplace=True)\n",
    "user_google = user_google.groupby(['user_id','name','creation','review_count'])['stars'].mean().reset_index()\n",
    "user_google = user_google.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in user_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    user_google[column] = user_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla bussiness_yelp\n",
    "cursor = conexion.cursor()\n",
    "for index, row in user_google.iterrows():\n",
    "    cursor.execute(\"INSERT INTO user_google (user_id, name, creation, review_count, stars) VALUES (%s, %s, %s, %s, %s)\",\n",
    "                (row['user_id'], row['name'], row['creation'], row['review_count'], row['stars']))\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Bussiness google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "business_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\5_bussiness_google.parquet.gz')\n",
    "\n",
    "\n",
    "business_google.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"California\", 2)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_google['name'] = business_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_google.dropna(inplace=True)\n",
    "business_google = business_google.drop_duplicates(subset=['gmap_id'], keep='first')\n",
    "business_google.drop(22003,inplace=True)\n",
    "business_google['avg_stars'] = business_google['avg_stars'].round(2)\n",
    "\n",
    "business_google = business_google[business_google['gmap_id'].isin(categories_google['gmap_id'].unique())]\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_google[column] = business_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in business_google[['gmap_id', 'name', 'latitude', 'longitude', 'avg_stars', 'state_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO business_google (gmap_id, name, latitude, longitude, avg_stars, state_id) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Business yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "business_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\6_bussiness_yelp.parquet.gz')\n",
    "\n",
    "business_yelp.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_yelp.rename(columns={'stars': 'avg_stars'}, inplace=True)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"California\", 2)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_yelp['name'] = business_yelp['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_yelp.dropna(inplace=True)\n",
    "business_yelp = business_yelp.drop_duplicates(subset=['business_id'], keep='first')\n",
    "business_yelp['avg_stars'] = business_yelp['avg_stars'].round(2)\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_yelp[column] = business_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in business_yelp[['business_id', 'name', 'latitude', 'longitude', 'avg_stars', 'state_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO business_yelp (business_id, name, latitude, longitude, avg_stars, state_id) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Categories google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "\n",
    "categories_google = categories_google[categories_google['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_google = categories_google[categories_google['gmap_id'].isin(business_google['gmap_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_google[column] = categories_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "    \n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in categories_google[['gmap_id', 'categories_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO categories_google (gmap_id, categories_id) VALUES (%s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Categories yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Conexión establecida correctamente!\n"
     ]
    }
   ],
   "source": [
    "categories_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\8_categories_yelp.parquet.gz')\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_yelp[column] = categories_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "conexion = conectar_mysql()\n",
    "\n",
    "# Insertar filas en la tabla business_yelp por lotes\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Convertir el DataFrame a una lista de tuplas para la inserción en lotes\n",
    "data_to_insert = [tuple(row) for row in categories_yelp[['business_id', 'categories_id']].to_numpy()]\n",
    "\n",
    "# Consulta de inserción\n",
    "insert_query = \"INSERT INTO categories_yelp (business_id, categories_id) VALUES (%s, %s)\"\n",
    "\n",
    "# Insertar en lotes utilizando executemany()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Hacer commit de los cambios\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Reviews google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\9_reviews_google.parquet.gz')\n",
    "\n",
    "reviews_google['date'] = reviews_google['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "reviews_google['resp_date'] = reviews_google['resp_date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_google['user_id'] = reviews_google['user_id'].astype(str)\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "reviews_google.loc[reviews_google['resp_date'].isna(), 'resp_date'] = reviews_google.loc[reviews_google['resp_date'].isna(), 'date']\n",
    "\n",
    "\n",
    "def round_resp_sentiment(value):\n",
    "    if value < -0.5:\n",
    "        return 0\n",
    "    elif -0.5 <= value < 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].apply(round_resp_sentiment)\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].astype(str)\n",
    "\n",
    "\n",
    "# export\n",
    "# reviews_google.to_csv(r'reviews_google.csv',encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_google.csv'\n",
    "INTO TABLE reviews_google\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, gmap_id, stars, sentiment, date, resp_sentiment, resp_date);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Reviews yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\10_reviews_yelp.parquet.gz')\n",
    "\n",
    "reviews_yelp['date'] = reviews_yelp['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['user_id'].isin(user_yelp['user_id'])]\n",
    "\n",
    "\n",
    "reviews_yelp.to_csv(r'reviews_yelp.csv',encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pUycOfUwM8vqX7KjRRhUEA</td>\n",
       "      <td>59MxRhNVhU9MYndMkz0wtw</td>\n",
       "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-25 07:31:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qRhOkdYNO1URgn1WJfK1cg</td>\n",
       "      <td>59MxRhNVhU9MYndMkz0wtw</td>\n",
       "      <td>W7gSJz80DywKnPRIGjA2Bw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-25 07:20:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZZbpYMY4s8sVQGEU1jAuVA</td>\n",
       "      <td>59MxRhNVhU9MYndMkz0wtw</td>\n",
       "      <td>l_slvEnh4v3W8BXF1gYlcQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-23 00:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_Ub20uO1MKy4XOVPOdzpqw</td>\n",
       "      <td>lUYboGI6aFbZ0dX27pijpA</td>\n",
       "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-28 01:04:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-DjIfoNFAiT5J4kF9hXocQ</td>\n",
       "      <td>SrfDRvGKI8FQq9LCr0dQuQ</td>\n",
       "      <td>gebiRewfieSdtt17PTW6Zg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-14 23:31:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909981</th>\n",
       "      <td>HVYhSbKGyj2R39fTDY7sGg</td>\n",
       "      <td>7KBaoiKUhdTvOsRFOMGwZw</td>\n",
       "      <td>VnAJnVpXHOIBdg6qFJBc3g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-19 02:30:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909982</th>\n",
       "      <td>CzJMAaOokvASWgVZg8B__w</td>\n",
       "      <td>L-h5y32VWEV60QXuDPW-hg</td>\n",
       "      <td>VnAJnVpXHOIBdg6qFJBc3g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-12 05:20:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909983</th>\n",
       "      <td>9_ztYeoSwdz7S9TW8xkDQA</td>\n",
       "      <td>03q-tEfa2aJtKhf00ZZ-hg</td>\n",
       "      <td>VnAJnVpXHOIBdg6qFJBc3g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-25 13:44:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909984</th>\n",
       "      <td>jDeNxby0ZI5UMsZzrywedA</td>\n",
       "      <td>NIlmQ38hxTR2w6lNSzJEuQ</td>\n",
       "      <td>VnAJnVpXHOIBdg6qFJBc3g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-06 01:52:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909985</th>\n",
       "      <td>rzwxu-a0JjzbGnIimpqBAg</td>\n",
       "      <td>1wx5T2GTopmtdHJZdqvWDQ</td>\n",
       "      <td>VnAJnVpXHOIBdg6qFJBc3g</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-02 13:54:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909986 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id                 user_id  \\\n",
       "0       pUycOfUwM8vqX7KjRRhUEA  59MxRhNVhU9MYndMkz0wtw   \n",
       "1       qRhOkdYNO1URgn1WJfK1cg  59MxRhNVhU9MYndMkz0wtw   \n",
       "2       ZZbpYMY4s8sVQGEU1jAuVA  59MxRhNVhU9MYndMkz0wtw   \n",
       "3       _Ub20uO1MKy4XOVPOdzpqw  lUYboGI6aFbZ0dX27pijpA   \n",
       "4       -DjIfoNFAiT5J4kF9hXocQ  SrfDRvGKI8FQq9LCr0dQuQ   \n",
       "...                        ...                     ...   \n",
       "909981  HVYhSbKGyj2R39fTDY7sGg  7KBaoiKUhdTvOsRFOMGwZw   \n",
       "909982  CzJMAaOokvASWgVZg8B__w  L-h5y32VWEV60QXuDPW-hg   \n",
       "909983  9_ztYeoSwdz7S9TW8xkDQA  03q-tEfa2aJtKhf00ZZ-hg   \n",
       "909984  jDeNxby0ZI5UMsZzrywedA  NIlmQ38hxTR2w6lNSzJEuQ   \n",
       "909985  rzwxu-a0JjzbGnIimpqBAg  1wx5T2GTopmtdHJZdqvWDQ   \n",
       "\n",
       "                   business_id  stars  sentiment                 date  \n",
       "0       gebiRewfieSdtt17PTW6Zg    3.0          2  2016-07-25 07:31:06  \n",
       "1       W7gSJz80DywKnPRIGjA2Bw    5.0          2  2016-07-25 07:20:23  \n",
       "2       l_slvEnh4v3W8BXF1gYlcQ    5.0          2  2016-07-23 00:13:36  \n",
       "3       gebiRewfieSdtt17PTW6Zg    1.0          1  2017-06-28 01:04:59  \n",
       "4       gebiRewfieSdtt17PTW6Zg    3.0          1  2017-01-14 23:31:35  \n",
       "...                        ...    ...        ...                  ...  \n",
       "909981  VnAJnVpXHOIBdg6qFJBc3g    1.0          1  2021-08-19 02:30:16  \n",
       "909982  VnAJnVpXHOIBdg6qFJBc3g    1.0          1  2021-09-12 05:20:37  \n",
       "909983  VnAJnVpXHOIBdg6qFJBc3g    1.0          1  2021-04-25 13:44:37  \n",
       "909984  VnAJnVpXHOIBdg6qFJBc3g    1.0          1  2021-10-06 01:52:41  \n",
       "909985  VnAJnVpXHOIBdg6qFJBc3g    4.0          0  2021-04-02 13:54:12  \n",
       "\n",
       "[909986 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_google.csv'\n",
    "INTO TABLE reviews_google\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, gmap_id, stars, sentiment, date, resp_sentiment, resp_date);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOAD DATA INFILE 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\reviews_yelp.csv'\n",
    "INTO TABLE reviews_yelp\n",
    "CHARACTER SET utf8\n",
    "FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 LINES\n",
    "(review_id, user_id, business_id, stars, sentiment, date);'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
