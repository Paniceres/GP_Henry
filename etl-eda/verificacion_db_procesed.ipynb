{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pd.read_parquet(r'..\\datasets\\processed\\bd\\1_states.parquet.gz')\n",
    "\n",
    "\n",
    "\n",
    "state.to_parquet(r'..\\datasets\\processed\\bd\\1_states.parquet.gz', compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_parquet(r'..\\datasets\\processed\\bd\\2_categories.parquet.gz')\n",
    "\n",
    "# Aplicar strip() a la columna 'name' para eliminar espacios en blanco adicionales\n",
    "categories['name'] = categories['name'].str.strip()\n",
    "\n",
    "# Convertir la columna 'name' a min√∫sculas para uniformizar los datos\n",
    "categories['name'] = categories['name'].str.lower()\n",
    "\n",
    "# Eliminar las filas duplicadas basadas en la columna 'name'\n",
    "categories.drop_duplicates(subset=['name'], keep='first', inplace=True)\n",
    "\n",
    "categories.to_parquet(r'..\\datasets\\processed\\bd\\2_categories.parquet.gz',compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\3_user_yelp.parquet.gz')\n",
    "user_yelp['creation'] = user_yelp['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "user_yelp.to_parquet(r'..\\datasets\\processed\\bd\\3_user_yelp.parquet.gz',compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\4_user_google.parquet.gz')\n",
    "user_google['creation'] = user_google['creation'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "user_google.drop_duplicates(inplace=True)\n",
    "user_google['user_id'] = user_google['user_id'].astype(str)\n",
    "user_google['name'] = user_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "user_google.drop(2023700,inplace=True)\n",
    "user_google.dropna(inplace=True)\n",
    "user_google = user_google.groupby(['user_id','name','creation','review_count'])['stars'].mean().reset_index()\n",
    "user_google = user_google.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "user_google.to_parquet(r'..\\datasets\\processed\\bd\\4_user_google.parquet.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "business_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\5_business_google.parquet.gz')\n",
    "\n",
    "\n",
    "business_google.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"California\", 2)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_google[\"state_id\"] = business_google[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_google['name'] = business_google['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_google.dropna(inplace=True)\n",
    "business_google = business_google.drop_duplicates(subset=['gmap_id'], keep='first')\n",
    "business_google.drop(22003,inplace=True)\n",
    "business_google['avg_stars'] = business_google['avg_stars'].round(2)\n",
    "\n",
    "business_google = business_google[business_google['gmap_id'].isin(categories_google['gmap_id'].unique())]\n",
    "\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_google[column] = business_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "business_google.to_parquet(r'..\\datasets\\processed\\bd\\5_business_google.parquet.gz', compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\6_business_yelp.parquet.gz')\n",
    "\n",
    "business_yelp.rename(columns={'state': 'state_id'}, inplace=True)\n",
    "business_yelp.rename(columns={'stars': 'avg_stars'}, inplace=True)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Florida\", 1)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"California\", 2)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"Illinois\", 3)\n",
    "business_yelp[\"state_id\"] = business_yelp[\"state_id\"].replace(\"New Jersey\", 4)\n",
    "business_yelp['name'] = business_yelp['name'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "business_yelp.dropna(inplace=True)\n",
    "business_yelp = business_yelp.drop_duplicates(subset=['business_id'], keep='first')\n",
    "business_yelp['avg_stars'] = business_yelp['avg_stars'].round(2)\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in business_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    business_yelp[column] = business_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "business_yelp.to_parquet(r'..\\datasets\\processed\\bd\\6_business_yelp.parquet.gz',compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz')\n",
    "\n",
    "categories_google = categories_google[categories_google['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_google = categories_google[categories_google['gmap_id'].isin(business_google['gmap_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_google.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_google[column] = categories_google[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "categories_google.to_parquet(r'..\\datasets\\processed\\bd\\7_categories_google.parquet.gz',compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\8_categories_yelp.parquet.gz')\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "def corregir_codificacion(texto):\n",
    "    try:\n",
    "        return texto.encode('latin-1').decode('utf-8', 'ignore')\n",
    "    except Exception:\n",
    "        return unicodedata.normalize('NFKD', texto).encode('latin-1', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "# Recorre todas las columnas del DataFrame\n",
    "for column in categories_yelp.columns:\n",
    "    # Intenta corregir los caracteres no codificados como UTF-8 en cada celda\n",
    "    categories_yelp[column] = categories_yelp[column].apply(lambda x: corregir_codificacion(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "categories_yelp.to_parquet(r'..\\datasets\\processed\\bd\\8_categories_yelp.parquet.gz', compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_google = pd.read_parquet(r'..\\datasets\\processed\\bd\\9_reviews_google.parquet.gz')\n",
    "\n",
    "reviews_google['date'] = reviews_google['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "reviews_google['resp_date'] = reviews_google['resp_date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_google['user_id'] = reviews_google['user_id'].astype(str)\n",
    "\n",
    "categories_yelp = categories_yelp[categories_yelp['categories_id'].isin(categories['categories_id'])]\n",
    "\n",
    "reviews_google.loc[reviews_google['resp_date'].isna(), 'resp_date'] = reviews_google.loc[reviews_google['resp_date'].isna(), 'date']\n",
    "\n",
    "\n",
    "def round_resp_sentiment(value):\n",
    "    if value < -0.5:\n",
    "        return 0\n",
    "    elif -0.5 <= value < 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].apply(round_resp_sentiment)\n",
    "reviews_google['resp_sentiment'] = reviews_google['resp_sentiment'].astype(str)\n",
    "\n",
    "reviews_google.to_parquet(r'..\\datasets\\processed\\bd\\9_reviews_google.parquet.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_yelp = pd.read_parquet(r'..\\datasets\\processed\\bd\\10_reviews_yelp.parquet.gz')\n",
    "\n",
    "reviews_yelp['date'] = reviews_yelp['date'].dt.strftime('%Y-%m-%d %H:%M:%S').str.replace('\\r', '')\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['business_id'].isin(business_yelp['business_id'])]\n",
    "\n",
    "reviews_yelp = reviews_yelp[reviews_yelp['user_id'].isin(user_yelp['user_id'])]\n",
    "\n",
    "reviews_yelp.to_parquet(r'..\\datasets\\processed\\bd\\10_reviews_yelp.parquet.gz',compression='gzip',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
