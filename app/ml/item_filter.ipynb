{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando nltk para procesar las categorias, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Funcion que realiza tokeinizacion en base a un texto.\n",
    "\n",
    "    Args:\n",
    "        text (string): Palabra u oración para aplicar la tokeinizacin.\n",
    "\n",
    "    Returns:\n",
    "        str: Serie de strings.\n",
    "    \"\"\"\n",
    "    # Aplico la teokeinizacion\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    words = [ps.stem(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "\n",
    "def obtener_palabras_similares(palabra, modelo, topn=3):\n",
    "    try:\n",
    "        similares = modelo.similar_by_word(palabra, topn=topn)\n",
    "        return [palabra for palabra, _ in similares]\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "def categories_nlp():  \n",
    "    \"\"\"\n",
    "    Funcion que a partir de un dataframe con categorias de columna \"name\" aplica la funcion *process_text*\n",
    "\n",
    "    Returns:\n",
    "        TfidfVectorizer: Matriz TF-IDF represetando  la frecuencia de terminos ponderada por importancia.(necesaria para el modelo.)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Genero un dataframe que contenga, las categorias y los negocios para yelp y google.\n",
    "\n",
    "    # Cambiar por la lectura a la BD\n",
    "\n",
    "    local_categories_google = pd.read_parquet('../../datasets/processed/bd/7_categories_google.parquet.gz')\n",
    "\n",
    "    # Cambiar por la lectura a la BD\n",
    "    local_categories_yelp = pd.read_parquet('../../datasets/processed/bd/8_categories_yelp.parquet.gz')\n",
    "\n",
    "    #Si se lee de la base de datos business_id ya esta como nombre.\n",
    "    local_categories_google.rename(columns={'gmap_id':'business_id'},inplace=True)\n",
    "    local_categories = pd.concat([local_categories_google,local_categories_yelp])\n",
    "\n",
    "    # Cambiar por la lectura a la BD\n",
    "    categoires = pd.read_parquet('../../datasets/processed/bd/2_categories.parquet.gz')\n",
    "    local_categories = pd.merge(local_categories,categoires,on='categories_id',how='inner')\n",
    "    \n",
    "    #### Se genera el dataframe local_categories.#####\n",
    "    \n",
    "    \n",
    "    \n",
    "    local_categories['procceced'] = local_categories['name'].apply(process_text)\n",
    "\n",
    "    # Si hay mas clase ademas de restaur ej: pizza restaur borra restaur, si no deja igual\n",
    "    local_categories['procceced'] = local_categories['procceced'].apply(lambda x:x.replace('restaur','') if x!= 'restaur' else x)\n",
    "    local_categories['procceced'] = local_categories['procceced'].astype(str)\n",
    "    # Crear una matriz TF-IDF para medir la similitud del contenido\n",
    "    \n",
    "    from gensim.models import KeyedVectors\n",
    "\n",
    "    # Ruta al archivo GoogleNews-vectors-negative300.bin\n",
    "    ruta_modelo = '../../datasets/extras/model/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "    # Cargar el modelo\n",
    "    modelo = KeyedVectors.load_word2vec_format(ruta_modelo, binary=True,limit=500000)\n",
    "    \n",
    "    \n",
    "    local_categories['processed'] = local_categories['procceced'].apply(\n",
    "    lambda text: ' '.join(\n",
    "        [\n",
    "            ' '.join(obtener_palabras_similares(palabra.strip(), modelo)) \n",
    "            if palabra in text \n",
    "            else palabra \n",
    "            for palabra in text.split()\n",
    "        ]\n",
    "    )\n",
    "    )   \n",
    "    \n",
    "    local_categories = local_categories[['business_id','name','processed']]\n",
    "    local_categories.to_parquet('./datasets/locales_categories.parquet') # Guardo el dataset util\n",
    "\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(local_categories['processed'])\n",
    "    return tfidf_matrix\n",
    "\n",
    "    #Proceso para normalizar las categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gnero las categorias para luego procesarlas y guardarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero un dataframe que contenga, las categorias y los negocios para yelp y google.\n",
    "\n",
    "# Cambiar por la lectura a la BD\n",
    "\n",
    "local_categories_google = pd.read_parquet('../../datasets/processed/bd/7_categories_google.parquet.gz')\n",
    "\n",
    "# Cambiar por la lectura a la BD\n",
    "local_categories_yelp = pd.read_parquet('../../datasets/processed/bd/8_categories_yelp.parquet.gz')\n",
    "\n",
    "#Si se lee de la base de datos business_id ya esta como nombre.\n",
    "local_categories_google.rename(columns={'gmap_id':'business_id'},inplace=True)\n",
    "local_categories = pd.concat([local_categories_google,local_categories_yelp])\n",
    "\n",
    "# Cambiar por la lectura a la BD\n",
    "categoires = pd.read_parquet('../../datasets/processed/bd/2_categories.parquet.gz')\n",
    "local_categories = pd.merge(local_categories,categoires,on='categories_id',how='inner')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Hago el procesamiento de las categorias con NLTK y los exporto en un pkl\n",
    "categories_procceced = categories_nlp() \n",
    "with open('./tfidf_matrix.pkl', 'wb') as file:\n",
    "        pickle.dump(categories_procceced, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUACION DEL MODELO\n",
    "\n",
    "\n",
    "# Cargo la matriz generada del procesamiento\n",
    "with open('./tfidf_matrix.pkl', 'rb') as file:\n",
    "        tfidf_matrix = pickle.load(file)\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(tfidf_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=30)\n",
    "\n",
    "knn_model.fit(tfidf_matrix)\n",
    "local_categories = pd.read_parquet('./app/ml/datasets/locales_categories.parquet')\n",
    "idx = local_categories[local_categories['business_id'] == business_id].index[0]\n",
    "\n",
    "_, indices = knn_model.kneighbors(categories_procceced[idx])\n",
    "recommendations = local_categories['business_id'].iloc[indices[0][1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo de recomendacion usando similitudes con vecinos cercanos\n",
    "\n",
    "\n",
    "# Cargo la matriz generada del procesamiento\n",
    "with open('./tfidf_matrix.pkl', 'rb') as file:\n",
    "        tfidf_matrix = pickle.load(file)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Defino y entreno al modelo.\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=30)\n",
    "knn_model.fit(tfidf_matrix)\n",
    "\n",
    "# Guardo el modelo en un pkl\n",
    "with open('./modelo_knn.pkl', 'wb') as file:\n",
    "    pickle.dump(knn_model, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTRO POR DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que calcula la distancia entre dos punto en funcion de las coordenadas\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta funcion aplica la distancia hervesine para encontrar la distancia entre dos puntos a partir de sus coordenaadas.\n",
    "    \n",
    "    Args:\n",
    "        lat1 (float): Latitud del primer punto.\n",
    "        lon1 (float): Longitud del primer punto\n",
    "        lat2 (float: Latitud del segundo punto.\n",
    "        lon2 (float): Longitud del segundo punto.\n",
    "        \n",
    "    Returns:\n",
    "        float:Distancia en metros entre dos coordeandas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Radio de la Tierra en kilometros\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convierte las coordenadas de grados a radianes\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Diferencia de latitud y longitud\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Fórmula haversine\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    # Distancia en metros\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que a partir de un id de negocio y una lista ids retorna la distancia entre ese negocio y cada uno de los demas\n",
    "def distance(business_id,business_id_list,rang=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta funcion calcula a partir de un negocio y una lista de negocios, la distancia entre los puntos.\n",
    "\n",
    "    Args:\n",
    "        business_id(str): Id del negocio.\n",
    "        business_id_list(list): Lista con id de negocios.\n",
    "        rang(float,optional) : Maxima distancia(kilometros) sobre la cual se quiere devolver los negocios.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data frame de los negocios tomando en cuenta las distnacias\n",
    "    \"\"\"\n",
    "    \n",
    "    if rang:\n",
    "        filtro_distance = rang\n",
    "    else:   \n",
    "        filtro_distance = 300000000 #FIltro distancia en metros.\n",
    "    #Genero un dataframe con los restaurantes de google y yelp\n",
    "    \n",
    "    # Cambiar por la lectura a la BD, si se lee de ahi business_id ya esta como nombre\n",
    "    business_google=pd.read_parquet('../../datasets/processed/bd/5_business_google.parquet.gz') \n",
    "    business_google.rename(columns={'gmap_id':'business_id'},inplace=True) \n",
    "    \n",
    "    # Cambiar por la lectura a la BD\n",
    "    business_yelp=pd.read_parquet('../../datasets/processed/bd/6_business_yelp.parquet.gz') \n",
    "    \n",
    "    # si se lee de la base de datos cambiar stars de business_yelp por avg_stars\n",
    "    business = pd.concat([business_google[['business_id','name','avg_stars','latitude','longitude','state_id']],business_yelp[['business_id','name','avg_stars','latitude','longitude','state_id']]])\n",
    "    #Genero las coordenadas del local al que le quiero encontrar recomendaciones.\n",
    "    lat_origin,long_origin = business[business['business_id']==business_id]['latitude'].iloc[0],business[business['business_id']==business_id]['longitude'].iloc[0]\n",
    "    #Filtro solo por los restaurantes que pertenecen a las recomendaciones.\n",
    "    business = business[business['business_id'].isin(business_id_list)]\n",
    "    #Calculo la distancia de cada restuarante recomendado al inicial\n",
    "    business['distance'] = business.apply(lambda row: haversine(lat_origin, long_origin, row['latitude'], row['longitude']), axis=1)\n",
    "    #Aplico el filtro de distancia.\n",
    "    business = business[business['distance']<filtro_distance]\n",
    "    return business\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener recomendaciones\n",
    "def get_recommendations(business_id,rang=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funcion que a partir de un negocio, recomienda otros, en funcion de sus categorias usando el modelo KNN.\n",
    "    \n",
    "    Ags:\n",
    "        business_id(str) : id del negocio al cual se le quieren calcular recomendaciones.\n",
    "        rang(float,optional) :Rango de distancia para obtener las recomendaciones(kilometros).\n",
    "\n",
    "    Returns:\n",
    "        business_cat(pd.DataFrame):Data Frame con las recomendaciones junto no algunas caracteristicas del negocio.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargo el modelo\n",
    "    with open('./modelo_knn.pkl', 'rb') as file: \n",
    "        knn_model = pickle.load(file)\n",
    "        \n",
    "    with open('./tfidf_matrix.pkl', 'rb') as file:\n",
    "        categories_procceced = pickle.load(file)\n",
    "    \n",
    "    ######### categories_procceced podria ser un df importado  con todos los pasos anteriores.#########\n",
    "    local_categories = pd.read_parquet('./datasets/locales_categories.parquet')\n",
    "\n",
    "    idx = local_categories[local_categories['business_id'] == business_id].index[0]\n",
    "   \n",
    "    \n",
    "    \n",
    "    #Genero las recomendaciones.\n",
    "    _, indices = knn_model.kneighbors(categories_procceced[idx])\n",
    "    recommendations = local_categories['business_id'].iloc[indices[0][0:]]  # Excluye el propio restaurante\n",
    "    \n",
    "    #Calcula las distancias entre las recomendaciones y el local.\n",
    "    if rang:\n",
    "        business = distance(business_id,recommendations,rang)\n",
    "    else:\n",
    "        business = distance(business_id,recommendations)\n",
    "    business = business[business['distance']!=0.0] # Elimino al restaurante mismos.\n",
    "    #Uno las caractereisticas de los locales, con las categorias.\n",
    "    business_cat = pd.merge(local_categories,business,on='business_id')\n",
    "    business_cat = business_cat.groupby('business_id').agg({\n",
    "        'latitude':'first',\n",
    "        'longitude':'first',\n",
    "        'name_x':list,\n",
    "        'name_y':'first',\n",
    "        'distance':'first',\n",
    "        'avg_stars':'mean',\n",
    "        'state_id':'first'\n",
    "        \n",
    "    }).reset_index().rename(columns =({'name_x':'category','name_y':'name'}))\n",
    "        \n",
    "    \n",
    "    return business_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTRO POR USUARIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que recibe un business id userid o categoria y recomienda locales, tambien puede agregarse el rango en metros de distancia.\n",
    "def recommendation(business_ids=None,user_id=None,category=None,distance=None,state=None):\n",
    "    \"\"\"\n",
    "    Esta funcion a partird e un negocio usuario o categoria recomienda otros negocios, teniendo en cuenta la distancia de ser requerida.\n",
    "    Para esto la funcion toma un negocio, o selecciona una lista de ellos usando user_id, y categorias, y aplica la funcion *get_recommendations*\n",
    "\n",
    "    Args:\n",
    "        business_ids (str, optional): Id de un negocio.\n",
    "        user_id (str, optional): Id de un usuario.\n",
    "        category (str, optional): Categoria (nombre).\n",
    "        distance (float, optional): Distancia en kilometros.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data Frame con ñas recomendaciones y otras caracteristicas(analizar el uso de json)\n",
    "    \"\"\"\n",
    "        \n",
    "    if business_ids:\n",
    "        business_ids = [business_ids]\n",
    "    \n",
    "    if user_id:\n",
    "        \n",
    "        # Cambiar por la lectura a la BD\n",
    "        df_rg = pd.read_parquet('../../datasets/processed/bd/9_reviews_google.parquet.gz',columns=['user_id','gmap_id','sentiment'])\n",
    "        df_ry = pd.read_parquet('../../datasets/processed/bd/10_reviews_yelp.parquet.gz',columns=['user_id','business_id','sentiment'])\n",
    "        df = pd.concat([df_rg,df_ry])\n",
    "        business_ids = df[df['user_id']==user_id].iloc[:10]['business_id'].tolist()\n",
    "        distance = None\n",
    "        if len(business_ids) == 0:\n",
    "            return 'Usuario no encontrado.'\n",
    "        \n",
    "    if category:\n",
    "        df_categories = pd.read_parquet('./datasets/locales_categories.parquet')\n",
    "        business_ids = df_categories[df_categories['name'].str.lower().str.contains(category.lower())].sample(10).iloc[:10]['business_id'].tolist()\n",
    "        distance = None\n",
    "        if len(business_ids) == 0:\n",
    "            return 'Categoria no encontrada.'\n",
    "        \n",
    "        \n",
    "    business_cat = pd.DataFrame()\n",
    "    \n",
    "    for business_id in business_ids:\n",
    "        business_cat = pd.concat([get_recommendations(business_id,rang=distance),business_cat])    \n",
    "        \n",
    "    if business_cat.shape[0] == 0:\n",
    "        return 'Restaurante no encontrado.'\n",
    "    \n",
    "    states = pd.read_parquet('../../datasets/processed/bd/1_states.parquet.gz')\n",
    "    business_cat = pd.merge(business_cat,states,on='state_id',how='inner')\n",
    "    business_cat = business_cat[['business_id','name','category','state','latitude','longitude','avg_stars','distance']]\n",
    "    if state:\n",
    "        business_cat = business_cat[business_cat['state']==state]\n",
    "        \n",
    "    return business_cat.sort_values(by=['distance','avg_stars'],ascending=[True,False]).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gmap_id, name, latitude, longitude, avg_stars, state_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_google=pd.read_parquet('../../datasets/processed/bd/5_business_google.parquet.gz') \n",
    "\n",
    "business_google[business_google['gmap_id'] == '0x809042411231551b:0x891040c09bbc3f9b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories_id</th>\n",
       "      <th>business_id_int</th>\n",
       "      <th>name</th>\n",
       "      <th>procceced</th>\n",
       "      <th>weighted_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x88db4147b1d9e6f3:0x943dbd10a92ba1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>restaur</td>\n",
       "      <td>0.01 restaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x8890b9241e704667:0x3a1e565c17c00993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>restaur</td>\n",
       "      <td>0.01 restaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x88e635378f43352f:0xa1b53c63436fa428</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>restaur</td>\n",
       "      <td>0.01 restaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x88d9b86c23bb04eb:0x2a82da546b7feb1b</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>restaur</td>\n",
       "      <td>0.01 restaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x88d9ba5d65937567:0xbc27649cf513cc89</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>restaur</td>\n",
       "      <td>0.01 restaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203650</th>\n",
       "      <td>vV57YWbrHqm1iylWmIdwVA</td>\n",
       "      <td>1653</td>\n",
       "      <td>66978</td>\n",
       "      <td>Botanical Gardens</td>\n",
       "      <td>botan garden</td>\n",
       "      <td>1.0 botan 1.0 garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203651</th>\n",
       "      <td>y7P06O7ypUgdU5fgV4s87Q</td>\n",
       "      <td>1654</td>\n",
       "      <td>58724</td>\n",
       "      <td>Newspapers &amp; Magazines</td>\n",
       "      <td>newspap magazin</td>\n",
       "      <td>1.0 newspap 1.0 magazin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203652</th>\n",
       "      <td>jchZL8NJP9YBwgFmrSdpfQ</td>\n",
       "      <td>1655</td>\n",
       "      <td>67246</td>\n",
       "      <td>Parking</td>\n",
       "      <td>park</td>\n",
       "      <td>1.0 park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203653</th>\n",
       "      <td>9295K2aKOltQSSTpm_7DBQ</td>\n",
       "      <td>1656</td>\n",
       "      <td>67285</td>\n",
       "      <td>Georgian</td>\n",
       "      <td>georgian</td>\n",
       "      <td>1.0 georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203654</th>\n",
       "      <td>-46lOITML86TZkk2fErq6A</td>\n",
       "      <td>1657</td>\n",
       "      <td>67730</td>\n",
       "      <td>Rest Stops</td>\n",
       "      <td>rest stop</td>\n",
       "      <td>1.0 rest 1.0 stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203655 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  business_id  categories_id  business_id_int  \\\n",
       "0       0x88db4147b1d9e6f3:0x943dbd10a92ba1b1              0                0   \n",
       "1       0x8890b9241e704667:0x3a1e565c17c00993              0                1   \n",
       "2       0x88e635378f43352f:0xa1b53c63436fa428              0                2   \n",
       "3       0x88d9b86c23bb04eb:0x2a82da546b7feb1b              0                3   \n",
       "4       0x88d9ba5d65937567:0xbc27649cf513cc89              0                4   \n",
       "...                                       ...            ...              ...   \n",
       "203650                 vV57YWbrHqm1iylWmIdwVA           1653            66978   \n",
       "203651                 y7P06O7ypUgdU5fgV4s87Q           1654            58724   \n",
       "203652                 jchZL8NJP9YBwgFmrSdpfQ           1655            67246   \n",
       "203653                 9295K2aKOltQSSTpm_7DBQ           1656            67285   \n",
       "203654                 -46lOITML86TZkk2fErq6A           1657            67730   \n",
       "\n",
       "                          name        procceced      weighted_categories  \n",
       "0                   Restaurant          restaur             0.01 restaur  \n",
       "1                   Restaurant          restaur             0.01 restaur  \n",
       "2                   Restaurant          restaur             0.01 restaur  \n",
       "3                   Restaurant          restaur             0.01 restaur  \n",
       "4                   Restaurant          restaur             0.01 restaur  \n",
       "...                        ...              ...                      ...  \n",
       "203650       Botanical Gardens     botan garden     1.0 botan 1.0 garden  \n",
       "203651  Newspapers & Magazines  newspap magazin  1.0 newspap 1.0 magazin  \n",
       "203652                 Parking             park                 1.0 park  \n",
       "203653                Georgian         georgian             1.0 georgian  \n",
       "203654              Rest Stops        rest stop        1.0 rest 1.0 stop  \n",
       "\n",
       "[203655 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories = pd.read_parquet('./datasets/locales_categories.parquet')\n",
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Henry_PF\\GP_Henry\\app\\ml\\item_filter.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m recommendation(business_ids\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpizza\u001b[39;49m\u001b[39m'\u001b[39;49m,distance\u001b[39m=\u001b[39;49m\u001b[39m100000.0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Henry_PF\\GP_Henry\\app\\ml\\item_filter.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m business_cat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m business_id \u001b[39min\u001b[39;00m business_ids:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     business_cat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([get_recommendations(business_id,rang\u001b[39m=\u001b[39;49mdistance),business_cat])    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m business_cat\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mRestaurante no encontrado.\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32mc:\\Henry_PF\\GP_Henry\\app\\ml\\item_filter.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m######### categories_procceced podria ser un df importado  con todos los pasos anteriores.#########\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m local_categories \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m'\u001b[39m\u001b[39m./datasets/locales_categories.parquet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m idx \u001b[39m=\u001b[39m local_categories[local_categories[\u001b[39m'\u001b[39;49m\u001b[39mbusiness_id\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m business_id]\u001b[39m.\u001b[39;49mindex[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#Genero las recomendaciones.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Henry_PF/GP_Henry/app/ml/item_filter.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m _, indices \u001b[39m=\u001b[39m knn_model\u001b[39m.\u001b[39mkneighbors(categories_procceced[idx])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5365\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5363\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key)\n\u001b[1;32m-> 5365\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[0;32m   5367\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   5368\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5369\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_slice(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "recommendation(business_ids='pizza',distance=100000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHORA INTENTAMOS CON WORDVEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Ruta al archivo GoogleNews-vectors-negative300.bin\n",
    "ruta_modelo = '../../datasets/extras/model/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "# Cargar el modelo\n",
    "modelo = KeyedVectors.load_word2vec_format(ruta_modelo, binary=True,limit=500000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_palabras_similares(palabra, modelo, topn=3):\n",
    "    try:\n",
    "        similares = modelo.similar_by_word(palabra, topn=topn)\n",
    "        return [palabra for palabra, _ in similares]\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obtener_palabras_similares('restaurant',modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_categories.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_categories['processed'] = local_categories['procceced'].apply(\n",
    "    lambda text: ' '.join(\n",
    "        [\n",
    "            ' '.join(obtener_palabras_similares(palabra.strip(), modelo)) \n",
    "            if palabra in text \n",
    "            else palabra \n",
    "            for palabra in text.split()\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_categories.loc[local_categories['processed'] == '', 'processed'] = 'restaur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_categories.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(local_categories['processed'])\n",
    "\n",
    "\n",
    "\n",
    "#Defino y entreno al modelo.\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "knn_model.fit(tfidf_matrix)\n",
    "\n",
    "# Guardo el modelo en un pkl\n",
    "with open('./model/modelo_knn.pkl', 'wb') as file:\n",
    "    pickle.dump(knn_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero las recomendaciones.\n",
    "_, indices = knn_model.kneighbors(tfidf_matrix[106106])\n",
    "recommendations = local_categories['business_id'].iloc[indices[0][1:]]  # Excluye el propio restaurante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_categories.iloc[106106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_categories[local_categories['business_id']=='0x88d905f9b0dccd0d:0x189d7a76056de69a']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
